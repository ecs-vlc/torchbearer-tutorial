{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart torchbearer\n",
    "\n",
    "This notebook will give a quick intro to training PyTorch models with torchbearer and how it differs from base PyTorch. \n",
    "\n",
    "We’ll need to load in some data and define a model, then we can train it with a standard PyTorch training loop and with torchbearer to see how it compares.\n",
    "\n",
    "Before we do that, lets import all the packages we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Now lets build our dataloader. We'll use the CIFAR10 dataset from torchvision and create training and testing dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                 std=[1, 1, 1])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data/cifar', train=True, download=True,\n",
    "                                        transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "traingen =  torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False) \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data/cifar', train=False, download=True,\n",
    "                                       transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "testgen = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Model\n",
    "\n",
    "Now lets build our model. Here is a 3 layer CNN with batchnorm, ReLU activations and a final linear layer to classify to CIFAR10s 10 classes. We also create the optimizer and define the criterion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, stride=2, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, stride=2, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, stride=2, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(576, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, 576)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "model = SimpleModel().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch training loop\n",
    "\n",
    "Here is a standard PyTorch training loop for this type of task. We have to loop over epochs, manage our dataloader, make sure to send tensors to the right devices and manage losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 390, Running Loss: 1.1008373282147125\n",
      " **** Finished Training **** \n",
      "\n",
      "Accuracy of the model on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "nEpoch = 2\n",
    "for epoch in range(nEpoch):  # loop over the dataset multiple times\n",
    "    trainloader = iter(traingen)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss = 0.99 * running_loss + 0.01 * loss.item()\n",
    "        print(\"Epoch: {}, Batch: {}, Running Loss: {}\".format(epoch, i, running_loss), end='\\r')\n",
    "\n",
    "print('\\n **** Finished Training **** \\n')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testgen:\n",
    "    images, labels = data\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    outputs = model(images.cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (\n",
    "    100*correct / total))\n",
    "\n",
    "# Reset the model and optimiser \n",
    "model = SimpleModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchbearer Training \n",
    "\n",
    "We can see that the PyTorch loop takes quite a few lines. Instead, in torchbearer we can achieve the same result with just 4 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0/2(t): 100%|██████████| 391/391 [00:06<00:00, 56.22it/s, running_acc=0.539, running_loss=1.28, acc=0.458, acc_std=0.498, loss=1.51, loss_std=0.249]\n",
      "0/2(v): 100%|██████████| 79/79 [00:01<00:00, 64.59it/s, val_acc=0.526, val_acc_std=0.499, val_loss=1.3, val_loss_std=0.0798]\n",
      "1/2(t): 100%|██████████| 391/391 [00:07<00:00, 55.56it/s, running_acc=0.621, running_loss=1.08, acc=0.589, acc_std=0.492, loss=1.16, loss_std=0.101]\n",
      "1/2(v): 100%|██████████| 79/79 [00:01<00:00, 64.78it/s, val_acc=0.583, val_acc_std=0.493, val_loss=1.17, val_loss_std=0.0956]\n"
     ]
    }
   ],
   "source": [
    "from torchbearer import Trial\n",
    "\n",
    "torchbearer_trial = Trial(model, optimizer, criterion, metrics=['acc', 'loss']).to('cuda')\n",
    "torchbearer_trial.with_generators(train_generator=traingen, val_generator=testgen)\n",
    "_ = torchbearer_trial.run(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, we get running accuracy and loss metrics for training and validation, we don't need to worry about sending tensors to devices (we just send the trial) and we get a tqdm display to view progress. \n",
    "\n",
    "This tqdm is not built for notebooks but we can switch to one that is by explicitly passing a Tqdm callback with the tqdm_notebook module when initialising the trial and turning off the default printing (setting verbose=0) when calling run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfb90af358b4adb89750bb860f576a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='0/2(t)', max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b4003a295845f391e0fcfeda8e6f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='0/2(v)', max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341bb5fe05564ecaba146a0c60847dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1/2(t)', max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495859885b5b49c2860baba02ac3f06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1/2(v)', max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchbearer.callbacks import Tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "torchbearer_trial = Trial(model, optimizer, criterion, metrics=['acc', 'loss'], callbacks=[Tqdm(tqdm_notebook)]).to('cuda')\n",
    "torchbearer_trial.with_generators(train_generator=traingen, val_generator=testgen)\n",
    "_=torchbearer_trial.run(2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might see new lines between each tqdm bar, this is apparently a dependancy problem between jupyter and tqdm and will get fixed eventually (probably). \n",
    "\n",
    "You can go [here](<https://torchbearer.readthedocs.io/en/latest/examples/quickstart.html>) for a slightly different version of this guide and for other examples of using torchbearer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on\n",
    "\n",
    "The next notebook is the function optimisation notebook where we'll look at a slightly different problem and see how to create torchbearer metrics which form the trial outputs for logging (eg to tensorboard or visdom) and display (tqdm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
